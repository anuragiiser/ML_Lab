# -*- coding: utf-8 -*-
"""Assignment_3_ML_lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oaVzFpTpoi-MhHKfNfscPxrTCcxX64Mc

**Anurag Sharma (24AI91R01)**

## **Lab Assignment 3**

### <font color='blue'> Task - 1 [Marks 0] </font>:
Load the [Secondary Mushroom](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset) dataset using Pandas. This dataset has 20 features, and the target variable is binary, which indicates if the mushroom is edible or not
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from scipy.stats import norm
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_curve, auc

# loading the dataset from the link given on the uci website
df = pd.read_csv('https://archive.ics.uci.edu/static/public/848/data.csv')

df.head()

df.shape

"""### <font color='blue'> Task - 2 [Marks 1] </font>:
Check if there are duplicate entries in the data and missing values of features. Remove duplicate entries and handle entries having missing feature values using Imputation method(Like Mean, Mediaan, Mode etc).  
"""

df.duplicated().sum() # checking for duplicate entries

df = df.drop_duplicates() # removing duplicate entries

df.duplicated().sum()  # to confirm if duplicates are removed

df.isnull().sum() # count entries having missing features

# making lists of catergorical features and continuous features based on thier datatypes
categorical_features = df.select_dtypes(include=['object']).columns
print(categorical_features)
continuous_features = df.select_dtypes(include=['int64', 'float64']).columns
print(continuous_features)

# we fill missing values for numeric columns with the median
median = df[continuous_features].median()
df[continuous_features] = df[continuous_features].fillna(median)
print(median)
# we fill missing values for categorical columns with the mode
mode = df[categorical_features].mode().iloc[0]
df[categorical_features] = df[categorical_features].fillna(mode)

df.shape

df['class'].value_counts() # we count instances of each class

"""### <font color='blue'> Task - 3 [Marks 3] </font>:

1.Preprocess the dataset as required, i.e. feature scaling or standardization

2.Is the dataset balanced or imbalanced?

3.Split data into training and test set
"""

# We pre-process the dataset
le = LabelEncoder()
for feature in categorical_features:
    df[feature] = le.fit_transform(df[feature])

df.head()

df['class'].value_counts()

"""We find the dataset is slightly imbalanced. However, we can move further with this dataset."""

X = df.drop('class', axis=1).to_numpy()
Y = df['class'].to_numpy()

# splitting the dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)

"""### <font color='blue'> Task - 4 [Marks 7] </font>:

Implement Naive Bayes’ classifier from scratch on this dataset, by appropriately choosing the likelihood distribution for each feature. This dataset has mixed feature types (i.e. continuous and categorical features), and the likelihood distribution of each feature must consider the corresponding feature type. Mention the type of distribution you chose for each feature’s likelihood.  

"""

# Get indices of categorical features
categorical_feature_indices = [df.columns.get_loc(col) for col in categorical_features]

# Get indices of continuous features
continuous_feature_indices = [df.columns.get_loc(col) for col in continuous_features]

print("Categorical feature indices:", categorical_feature_indices)
print("Continuous feature indices:", continuous_feature_indices)

class NB_Classifier_Scratch:
    def __init__(self, categorical_features):
        # we initialize dictionaries to store prior probabilities and likelihoods
        self.p_prob = {}  # prior probabilities for each class
        self.lh = {}  # the likelihoods for feature values given each class
        self.categorical_features = categorical_features  # indices of categorical features

    def fit(self, X, y):
        self.classes = np.unique(y)  # we store unique class labels
        self.n_features = X.shape[1]  # features
        self.p_prob = self.cal_prior_prob(y) # we compute prior probabilities based on class frequencies
        self.lh = self.cal_lh(X, y)  # we compute likelihods for each feature value given for each class
        # print(self.classes)
        # print(self.n_features)

    def cal_prior_prob(self, y):
        # we calculate the prior probabilities of each class
        classes, counts = np.unique(y, return_counts=True)  # we get unique classes and their counts
        # print(classes)
        # print(counts)
        total_count = len(y)
        # calculationg prior probability for each class and storing as dictionary
        probs = dict(zip(classes, counts / total_count))
        return probs

    def cal_lh(self, X, y):
        # lh stores likelihoods for each class and feature (nested dictionary)
        lh = {}
        for cls in self.classes:
            lh[cls] = {}

        for cls in self.classes:
            X_cls = X[y == cls] # we filter the training data for the current class
            num_cls = X_cls.shape[0]  # Number of samples

            for idx in range(self.n_features):
                if idx in self.categorical_features:
                    feature_values, counts = np.unique(X_cls[:, idx], return_counts=True) #feature value counts and their probabilities
                    lh[cls][idx] = dict(zip(feature_values, counts / num_cls)) # likelihoods of feature values and their probabilities
                else:
                    mean = np.mean(X_cls[:, idx]) # mean for the Gaussian Distribution
                    variance = np.var(X_cls[:, idx]) # variance for the Gaussian Distribution
                    lh[cls][idx] = (mean, variance)
        return lh

    def predict(self, X):
        preds = []
        for i in X:
            # we initialize the scores for each class with the log of prior probabilities
            scores = {}
            for cls, prior in self.p_prob.items():
                scores[cls] = np.log(prior)
            for cls in self.classes:
                for idx, value in enumerate(i):
                    if idx in self.categorical_features:
                        # we get the likelihood of the feature value given the class
                        feature_lh = self.lh[cls].get(idx, {})
                        scores[cls] += np.log(feature_lh.get(value, 1e-10))
                    else:
                        mean, variance = self.lh[cls][idx] # mean and variance of the Gaussian Distribution
                        # we use Gaussian distribution to get the likelihoods
                        lh = norm.pdf(value, mean, np.sqrt(variance))
                        scores[cls] += np.log(lh + 1e-10)  # to avoid log(0) we add a small value 1e-10

            # we predict the class with the highest score
            predicted_cls = max(scores, key=scores.get)
            preds.append(predicted_cls)

        return np.array(preds)

# we initialize the indices of the categorical features
categorical_features = [2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]

nb_classifier =  NB_Classifier_Scratch(categorical_features=categorical_features)
# we fit the model on the training data
nb_classifier.fit(X_train, y_train)

"""### <font color='blue'> Task - 5 [Marks 2] </font>:

Report the classification performance using the appropriate metrics (accuracy, precision, recall, confusion matrix, AUPRC) using suitable plots.
"""

# prediction using scratch implementation
y_preds_scratch = nb_classifier.predict(X_test)

class_names = ['edible', 'not edible']  # replacing with actual class names
# confusion matrix
c_matrix = confusion_matrix(y_test, y_preds_scratch, labels=nb_classifier.classes)
print(c_matrix)
# classification report
c_report = classification_report(y_test, y_preds_scratch, target_names=class_names)
print(c_report)

# we plot the confusion matrix
plt.figure(figsize=(5, 4))
sns.heatmap(c_matrix, annot=True, fmt='d', cmap='RdPu', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# computing ROC curve and AUC
fpr, tpr, _ = roc_curve(y_test,y_preds_scratch)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='cyan', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

"""### <font color='blue'> Task - 6 [Marks 5] </font>:
Fit a Naive Bayes’ model for this dataset using MixedNB (from the package https://pypi.org/project/mixed-naive-bayes/)


"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install mixed-naive-bayes

from mixed_naive_bayes import MixedNB

# we fit the MixedNB model
model = MixedNB()
model.fit(X_train, y_train)

# predictions
y_pred = model.predict(X_test)

"""### <font color='blue'> Task - 7 [Marks 2] </font>:

Compare the performance obtained by your implementation with that obtained using MixedNB
"""

print("Performance obtained using MixedNB library: ")
class_names = ['edible', 'not edible']  # replacing with actual class names
# confusion matrix
c_matrix_NB = confusion_matrix(y_test, y_pred, labels=nb_classifier.classes)
print(c_matrix_NB)
# classification report
c_report_NB = classification_report(y_test, y_pred, target_names=class_names)
print(c_report_NB)

plt.figure(figsize=(5, 4))
sns.heatmap(c_matrix_NB, annot=True, fmt='d', cmap='Reds', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()


print("Performance obtained by using Scratch implementation: ")
print(c_matrix)
print(c_report)

plt.figure(figsize=(5, 4))
sns.heatmap(c_matrix, annot=True, fmt='d', cmap='BuGn', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Compute ROC curve and AUC
fpr, tpr, _ = roc_curve(y_preds_scratch, y_pred)
roc_auc = auc(fpr, tpr)

# ROC curve
plt.figure()
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='cyan', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('ROC')
plt.legend()
plt.show()